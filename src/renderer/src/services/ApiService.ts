import { getOpenAIWebSearchParams } from '@renderer/config/models'
import { EMOJI_GENERATOR_PROMPT, SEARCH_SUMMARY_PROMPT } from '@renderer/config/prompts'
import i18n from '@renderer/i18n'
import store from '@renderer/store'
import { setGenerating } from '@renderer/store/runtime'
import { Assistant, MCPTool, Message, Model, Provider, Suggestion } from '@renderer/types'
import { formatMessageError, isAbortError } from '@renderer/utils/error'
import { cloneDeep, findLast, isEmpty } from 'lodash'

import AiProvider from '../providers/AiProvider'
import {
  getAssistantProvider,
  getDefaultAssistant,
  getDefaultModel,
  getProviderByModel,
  getTopNamingModel,
  getTranslateModel
} from './AssistantService'
import { EVENT_NAMES, EventEmitter } from './EventService'
import { filterMessages, filterUsefulMessages } from './MessagesService'
import { estimateMessagesUsage } from './TokenService'
import WebSearchService from './WebSearchService'

export async function fetchChatCompletion({
  message,
  messages,
  assistant,
  onResponse
}: {
  message: Message
  messages: Message[]
  assistant: Assistant
  onResponse: (message: Message) => void
}) {
  const provider = getAssistantProvider(assistant)
  const webSearchProvider = WebSearchService.getWebSearchProvider()
  const AI = new AiProvider(provider)

  try {
    let _messages: Message[] = []
    let isFirstChunk = true
    let query = ''

    // Search web
    if (WebSearchService.isWebSearchEnabled() && assistant.enableWebSearch && assistant.model) {
      const webSearchParams = getOpenAIWebSearchParams(assistant, assistant.model)

      if (isEmpty(webSearchParams)) {
        const lastMessage = findLast(messages, (m) => m.role === 'user')
        const lastAnswer = findLast(messages, (m) => m.role === 'assistant')
        const hasKnowledgeBase = !isEmpty(lastMessage?.knowledgeBaseIds)

        if (lastMessage) {
          if (hasKnowledgeBase) {
            window.message.info({
              content: i18n.t('message.ignore.knowledge.base'),
              key: 'knowledge-base-no-match-info'
            })
          }

          // æ›´æ–°æ¶ˆæ¯çŠ¶æ€ä¸ºæœç´¢ä¸­
          onResponse({ ...message, status: 'searching' })

          try {
            // ç­‰å¾…å…³é”®è¯ç”Ÿæˆå®Œæˆ
            const searchSummaryAssistant = getDefaultAssistant()
            searchSummaryAssistant.model = assistant.model || getDefaultModel()
            searchSummaryAssistant.prompt = SEARCH_SUMMARY_PROMPT

            // å¦‚æœå¯ç”¨æœç´¢å¢å¼ºæ¨¡å¼ï¼Œåˆ™ä½¿ç”¨æœç´¢å¢å¼ºæ¨¡å¼
            if (WebSearchService.isEnhanceModeEnabled()) {
              const keywords = await fetchSearchSummary({
                messages: lastAnswer ? [lastAnswer, lastMessage] : [lastMessage],
                assistant: searchSummaryAssistant
              })
              if (keywords) {
                query = keywords
              }
            } else {
              query = lastMessage.content
            }

            // ç­‰å¾…æœç´¢å®Œæˆ
            const webSearch = await WebSearchService.search(webSearchProvider, query)

            // å¤„ç†æœç´¢ç»“æœ
            message.metadata = {
              ...message.metadata,
              webSearch: webSearch
            }

            window.keyv.set(`web-search-${lastMessage?.id}`, webSearch)
          } catch (error) {
            console.error('Web search failed:', error)
          }
        }
      }
    }

    const lastUserMessage = findLast(messages, (m) => m.role === 'user')
    // Get MCP tools
    let mcpTools: MCPTool[] = []
    const enabledMCPs = lastUserMessage?.enabledMCPs

    if (enabledMCPs && enabledMCPs.length > 0) {
      const allMCPTools = await window.api.mcp.listTools()
      mcpTools = allMCPTools.filter((tool) => enabledMCPs.some((mcp) => mcp.name === tool.serverName))
    }

    await AI.completions({
      messages: filterUsefulMessages(messages),
      assistant,
      onFilterMessages: (messages) => (_messages = messages),
      onChunk: ({ text, reasoning_content, usage, metrics, search, citations, mcpToolResponse, generateImage }) => {
        message.content = message.content + text || ''
        message.usage = usage
        message.metrics = metrics

        if (reasoning_content) {
          message.reasoning_content = (message.reasoning_content || '') + reasoning_content
        }

        if (search) {
          message.metadata = { ...message.metadata, groundingMetadata: search }
        }

        if (mcpToolResponse) {
          message.metadata = { ...message.metadata, mcpTools: cloneDeep(mcpToolResponse) }
        }
        if (generateImage) {
          message.metadata = {
            ...message.metadata,
            generateImage: generateImage
          }
        }

        // Handle citations from Perplexity API
        if (isFirstChunk && citations) {
          message.metadata = {
            ...message.metadata,
            citations
          }
          isFirstChunk = false
        }

        onResponse({ ...message, status: 'pending' })
      },
      mcpTools: mcpTools
    })

    message.status = 'success'

    if (!message.usage || !message?.usage?.completion_tokens) {
      message.usage = await estimateMessagesUsage({
        assistant,
        messages: [..._messages, message]
      })
      // Set metrics.completion_tokens
      if (message.metrics && message?.usage?.completion_tokens) {
        if (!message.metrics?.completion_tokens) {
          message = {
            ...message,
            metrics: {
              ...message.metrics,
              completion_tokens: message.usage.completion_tokens
            }
          }
        }
      }
    }
    console.log('message', message)
  } catch (error: any) {
    if (isAbortError(error)) {
      message.status = 'paused'
    } else {
      message.status = 'error'
      message.error = formatMessageError(error)
    }
  }

  // Emit chat completion event
  EventEmitter.emit(EVENT_NAMES.RECEIVE_MESSAGE, message)
  onResponse(message)

  // Reset generating state
  store.dispatch(setGenerating(false))

  return message
}

interface FetchTranslateProps {
  message: Message
  assistant: Assistant
  onResponse?: (text: string) => void
}

export async function fetchTranslate({ message, assistant, onResponse }: FetchTranslateProps) {
  const model = getTranslateModel()

  if (!model) {
    throw new Error(i18n.t('error.provider_disabled'))
  }

  const provider = getProviderByModel(model)

  if (!hasApiKey(provider)) {
    throw new Error(i18n.t('error.no_api_key'))
  }

  const AI = new AiProvider(provider)

  try {
    return await AI.translate(message, assistant, onResponse)
  } catch (error: any) {
    return ''
  }
}

export async function fetchMessagesSummary({ messages, assistant }: { messages: Message[]; assistant: Assistant }) {
  const model = getTopNamingModel() || assistant.model || getDefaultModel()
  const provider = getProviderByModel(model)

  if (!hasApiKey(provider)) {
    return null
  }

  const AI = new AiProvider(provider)

  try {
    const text = await AI.summaries(filterMessages(messages), assistant)
    // Remove all quotes from the text
    return text?.replace(/["']/g, '') || null
  } catch (error: any) {
    return null
  }
}

export async function fetchSearchSummary({ messages, assistant }: { messages: Message[]; assistant: Assistant }) {
  const model = assistant.model || getDefaultModel()
  const provider = getProviderByModel(model)

  if (!hasApiKey(provider)) {
    return null
  }

  const AI = new AiProvider(provider)

  try {
    return await AI.summaryForSearch(messages, assistant)
  } catch (error: any) {
    return null
  }
}

export async function fetchGenerate({ prompt, content }: { prompt: string; content: string }): Promise<string> {
  const model = getDefaultModel()
  const provider = getProviderByModel(model)

  if (!hasApiKey(provider)) {
    return ''
  }

  const AI = new AiProvider(provider)

  try {
    return await AI.generateText({ prompt, content })
  } catch (error: any) {
    return ''
  }
}

/**
 * æ ¹æ®æç¤ºè¯ç”Ÿæˆemojiè¡¨æƒ…å»ºè®®
 * @param prompt æç¤ºè¯
 * @returns emojiè¡¨æƒ…
 */
export async function fetchEmojiSuggestion(prompt: string): Promise<string> {
  // å¦‚æœæç¤ºè¯ä¸ºç©ºï¼Œè¿”å›é»˜è®¤è¡¨æƒ…
  if (!prompt || prompt.trim() === '') {
    const defaultEmojis = ['ğŸ¤–', 'ğŸ’¡', 'âœ¨', 'ğŸ§ ', 'ğŸ“š']
    return defaultEmojis[Math.floor(Math.random() * defaultEmojis.length)]
  }

  try {
    // å°è¯•ä½¿ç”¨AIç”Ÿæˆemoji
    const model = getDefaultModel()
    const provider = getProviderByModel(model)

    if (!hasApiKey(provider)) {
      // å¦‚æœæ²¡æœ‰APIå¯†é’¥ï¼Œå›é€€åˆ°æœ¬åœ°ç”Ÿæˆæ–¹å¼
      const { generateEmojiFromPrompt } = await import('@renderer/utils')
      return await generateEmojiFromPrompt(prompt)
    }

    const AI = new AiProvider(provider)
    // ä½¿ç”¨emojiç”Ÿæˆæç¤ºè¯
    const result = await AI.generateText({
      prompt: EMOJI_GENERATOR_PROMPT,
      content: prompt
    })

    // ä»ç»“æœä¸­æå–emoji
    if (result.includes('Emoji:')) {
      const match = result.match(/Emoji:\s*([^\s]+)/)
      return match ? match[1] : result
    }
    
    return result
  } catch (error) {
    console.error('Error generating emoji from prompt:', error)
    // å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°ç”Ÿæˆæ–¹å¼
    try {
      const { generateEmojiFromPrompt } = await import('@renderer/utils')
      return await generateEmojiFromPrompt(prompt)
    } catch (e) {
      console.error('Fallback emoji generation also failed:', e)
      // å¦‚æœæœ¬åœ°ç”Ÿæˆä¹Ÿå¤±è´¥ï¼Œè¿”å›é»˜è®¤è¡¨æƒ…
      const defaultEmojis = ['ğŸ¤–', 'ğŸ’¡', 'âœ¨', 'ğŸ§ ', 'ğŸ“š']
      return defaultEmojis[Math.floor(Math.random() * defaultEmojis.length)]
    }
  }
}

export async function fetchSuggestions({
  messages,
  assistant
}: {
  messages: Message[]
  assistant: Assistant
}): Promise<Suggestion[]> {
  const model = assistant.model
  if (!model) {
    return []
  }

  if (model.owned_by !== 'graphrag') {
    return []
  }

  if (model.id.endsWith('global')) {
    return []
  }

  const provider = getAssistantProvider(assistant)
  const AI = new AiProvider(provider)

  try {
    return await AI.suggestions(filterMessages(messages), assistant)
  } catch (error: any) {
    return []
  }
}

// Helper function to validate provider's basic settings such as API key, host, and model list
export function checkApiProvider(provider: Provider): {
  valid: boolean
  error: Error | null
} {
  const key = 'api-check'
  const style = { marginTop: '3vh' }

  if (provider.id !== 'ollama' && provider.id !== 'lmstudio') {
    if (!provider.apiKey) {
      window.message.error({ content: i18n.t('message.error.enter.api.key'), key, style })
      return {
        valid: false,
        error: new Error(i18n.t('message.error.enter.api.key'))
      }
    }
  }

  if (!provider.apiHost) {
    window.message.error({ content: i18n.t('message.error.enter.api.host'), key, style })
    return {
      valid: false,
      error: new Error(i18n.t('message.error.enter.api.host'))
    }
  }

  if (isEmpty(provider.models)) {
    window.message.error({ content: i18n.t('message.error.enter.model'), key, style })
    return {
      valid: false,
      error: new Error(i18n.t('message.error.enter.model'))
    }
  }

  return {
    valid: true,
    error: null
  }
}

export async function checkApi(provider: Provider, model: Model) {
  const validation = checkApiProvider(provider)
  if (!validation.valid) {
    return {
      valid: validation.valid,
      error: validation.error
    }
  }

  const AI = new AiProvider(provider)

  const { valid, error } = await AI.check(model)

  return {
    valid,
    error
  }
}

function hasApiKey(provider: Provider) {
  if (!provider) return false
  if (provider.id === 'ollama' || provider.id === 'lmstudio') return true
  return !isEmpty(provider.apiKey)
}

export async function fetchModels(provider: Provider) {
  const AI = new AiProvider(provider)

  try {
    return await AI.models()
  } catch (error) {
    return []
  }
}

/**
 * Format API keys
 * @param value Raw key string
 * @returns Formatted key string
 */
export const formatApiKeys = (value: string) => {
  return value.replaceAll('ï¼Œ', ',').replaceAll(' ', ',').replaceAll(' ', '').replaceAll('\n', ',')
}
